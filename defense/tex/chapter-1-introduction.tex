%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Chapter: Introduction
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction} \label{ch:intro}
\section{Overview}
The persistent evolution of digital technology is unlocking new forms of Business Intelligence (BI). The acquisition, storage, access, and analysis of digital information provides knowledge and strategic insights for enterprise and research organizations. Each time we visit a website or make a transaction, the owner has the ability to log everything we do; every link we click, each form we submit, what time we log in and out, any errors we encounter, and just about anything else we can imagine. While this information may seem useless and doesn't appear to affect the user much, the site owner now has valuable information that can give him or her the competitive advantage. The collected data can be stored in log files and analyzed for BI that can be used to develop and incorporate new business strategies and direct planning for the future.

In terms of BI data management, collection is generally the easy part-- it is the storage and access aspects (requisites for later BI analytics) that impose major challenges for \textit{small and medium businesses} (SMB)-- especially since data can accumulate to gigabytes and even terabytes in a relatively short period of time. Thus, data management becomes a greater obstacle as more and more data needs to be collected and stored. Traditionally, businesses have been able to store their data in local data centers comprised of a few machines. However, as data outgrows the capacity of local data centers, they must modify their storage methods. Even if the company expands the data to multiple machines, they must develop ways of accessing the data. In BI, more data reveals new doors and opportunities for the organization in terms of derived knowledge and achieving a competitive advantage, but the information is effectively useless if they can't consider all of it simultaneously in their strategic analysis.

Providing a multi-layer model of staging, integration, and access to historical data archives is fundamental to BI for any modern organization. Staging is used to store raw data for use by developers, integration is used to incorporate data into the storage system while maintaining a level of abstraction from users, and the access layer is for getting data out for the end users. Due to the sensitive and irreplaceable nature of customer data, enterprise storage systems must provide data replication, backup and recovery, data integrity, and concurrency control. Common storage systems include data transformation algorithms to transform data to the correct format. The system interacts with the operating system to send the data from the user to the storage system. There are several database management systems which conform to these requirements, but the most popular is the \textit{relational database management system} (RDBMS). 

As the size of data sets increase, it is possible to run out of space on a single system. When this happens, the data may be moved to a parallel RDBMS or distributed among several networked systems and managed by a \textit{distributed data management system} (DDMS). Parallel RDBMSs have been commercially available for several decades and offer high performance and high availability for data management. However, the up-front costs and the cost to scale up for larger storage capacities can be expensive. On the other hand, freely available DDMSs offer high performance and high availability, but at much lower up-front and scaling costs.  

In this research, we investigate the performance of \textit{open-source software} (OSS) solutions on mid-sized data sets for SMBs using a realistic case study. We conduct this experiment between a RDBMS, namely MySQL, and a DDMS, namely Hadoop, which is a resource-effective solution for SMBs. We investigate MapReduce and Hive as two techniques for analyzing the data stored in Hadoop.

\section{Structure}
In Chapter~\ref{ch:background} we provide the background for concepts pertaining to BI storage, access, and analytical systems. Here, we outline some challenges faced by SMBs interested in BI analytics and discuss RDBMS and alternative DDMS solutions. We summarize the notion of Big Data, a likely future obstacle for the SMB, and provide relevant information regarding the Hadoop solutions considered in this research: MapReduce and Hive.

In Chapter~\ref{ch:problem} we introduce the payment history analysis case study for a specific SMB. This particular SMB designs software tools to analyze current and historical payment habits on customer data and attempts to forecast trends. We discuss the database management challenges faced by the SMB as their customer base expands and define their specific case study. Here, we explain their data storage and access models, along with the requisite test data set generation utilities required to conduct the analysis. In doing so, we formally present the problem statement and list the inquiries we wish to address in this research project.

In Chapter~\ref{ch:solution} we define the design and implementation for the RDBMS and DDMS solutions. First, we discuss the detailed process of generating the test data set and provide a summarized description of the key algorithms and data structures employed by these utilities: the \texttt{HistogramGen} and \texttt{AccountGen} MapReduce programs. Second, we discuss the central components of the MySQL, Hadoop MapReduce, and Hadoop Hive solution implementation, where we explain the process by which they are used to instrument the payment history analysis case study (as presented in Chapter~\ref{ch:problem}).

In Chapter~\ref{ch:results} we detail the RDBMS and DDMS performance comparison experiment (for the solutions from Chapter~\ref{ch:solution}). Here, we discuss the efficiency and scalability for these implementations, along with the resulting implications and analysis for this SMB's data management case study (as expressed in Chapter~\ref{ch:problem}). First, we discuss the software and hardware environment in which our comparative benchmark analysis is conducted. Second, we provide the procedure used to guide and execute the experiment. Finally, we present the performance results for the various experimental trial runs.

In Chapter~\ref{ch:conclusion} we conclude our report and suggest some future directions.